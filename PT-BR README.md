# ELT processing ALL in Azure Workspace
Exemplo de todo o processo de ingest√£o armazenamento, trasforma√ßao e visualiza√ß√£o.

Esse √© um reposit√≥rio de ELT com recursos do Azure para arquivos JSON publicado por Vitor Franklin de Lacerda Nimschofsky.
A ideia do projeto √© montar um ELT de um dado bruto ingerido inicialmente via api https://www.openbrewerydb.org/documentation, para que no final seja feita a visualiza√ß√£o de an√°lises no PowerBI.

RESUMO:

‚óè Atrav√©s de uma requisi√ß√£o feita no endpoint List Breweries - https://api.openbrewerydb.org/v1/breweries, obtive todos os dados de todos os pa√≠ses no total de 8206 registros em formato JSON.

‚óè Armazenei os registros no Azure Blob Storage em um conteiner Land.

‚óè Foi necess√°rio o uso do Azure Key Vault para criar alguns secrets e ocultar token e conex√µes nos nossos notebooks, visando sempre a conformidade e seguran√ßa.

‚óè Consumi esses arquivos JSON no Azure Databricks para fazer a estrutura√ß√£o do Data Lakehouse e fazer, tamb√©m, as transforma√ß√µes necess√°rias.
Utilizei o armazenamento Delta do databricks para estruturar a arquitetura de medalh√£o, me beneficiando da otimiza√ß√£o e rapidez do DBSF.
Ainda no Azure Databricks criei uma tabela bronze com o dataframe inicial sem transforma√ß√µes, na camada silver particionei a tabela inicial por pa√≠ses, onde criei tabelas Deltas na camada silver para cada pa√≠s separadamente.
Por fim na camada gold crio uma tabela delta final, para ser consumida no Power BI, onde ser√° mostrado alguns insights referentes a quantidade de "Lojas" por tipo de "Loja" e por localiza√ß√£o.

ARQUITETURA:

![arquitetura](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/db7b526f-2553-4e4a-9e52-3b8bd1b16a62)

CRIA√á√ÉO DE RECURSOS:

Resource Group -

![Captura de tela 2023-06-16 165129](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/6d08076c-c7a2-41c3-8484-5aa26a0820b8)

Azure Data Factory -

![cria√ß√£o do adf](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/55fbd588-31f6-4ba0-938a-8fbecddc3517)

Azure Key Vault - 

![cria√ß√£o da kv](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/7524f247-fff8-4adc-ad60-62a495dc368e)

Azure Databricks -

![cria√ß√£o databricks](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/832bac2d-2c3e-40c6-abb6-b0490d5167ed)

Azure Storage -

![storage](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/c9ad3cae-a774-4a87-b4c7-c56a5a3dd46c)

Cluster Databricks -

![cluster config](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/c5dc6601-1bad-4983-9c65-f5b8fda11afb)



Toda a arquitetura foi feita na nuvem do Azure, segui com a seguinte estrat√©gia:

‚óè Azure Data Factory: Utilizei para fazer a ingest√£o dos dados vindos da API p√∫blica, toda a esteira de dados √© feita com a ferramenta do Azure Data Factory.

![pipeline](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/38ab5806-6603-46aa-b31e-421612f01029)


O JSON da pipeline esta na pasta source-code, nesse JSON podemos ver com detalhes toda a configura√ß√£o da pipeline.

Como o endpoint de List Brewery - https://api.openbrewerydb.org/v1/breweries retorna valores paginados, foi necess√°rio o uso da atividade Until para conseguirmos requisitar todos os dados de Breweries, enquanto tivesse registros(dados) nas paginas subsequentes, a requisi√ß√£o continuaria, at√© o resultado da requisi√ß√£o vinher vazio. Registros de todos os pa√≠ses abaixo, foram requisitados dessa maneira:

Austria
England
France
Isle of Man
Ireland
Poland
Portugal
Scotland
South Korea
United States

Al√©m da requisi√ß√£o com a atividade copy data, que faz a requisi√ß√£o no source e copia os dados para o nosso blob(container land) no sink, utilizamos set variaveis iniciais para a primeira pagina e set variables tempor√°rias para atualizar as paginas subsequentes, finalizando o loop(ingest√£o e armazenamento),
a pipeline roda os tr√™s notebooks, bronze, silver e gold nesta sequ√™ncia.

‚óè Blob Storage: Aqui foi feito o armazenamento de todos os arquivos JSON. O conteiner land √© o destino de todo o fluxo de dados da Pipeline.

![land](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/4b168860-ff9e-470b-b294-628280b96044)


Criei uma variavel unix_timestamp, que gera din√¢micamente a current date data e hora em formato Unix, essa variavel vai servir para nomear o arquivo JSON com uma seguencia de numeros √∫nicos.
Utilizamos tamb√©m como subpasta a data do dia que a pipeline foi executada.

O file path do copy data do ADF para o blob foi esse abaixo:

![path blob](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/4061eee1-351e-404c-9034-f616776a8888)


‚óè Azure Key Vault: Na cria√ß√£o do mount point foi necess√°rio utilizar um token de conex√£o do storage, esse token foi armazenado na nossa secret blob-key.

‚óè Azure Databricks: Foram, criados tr√™s notebooks:

Brewery_Bronze l√™ os arquivos do blob e cria um dataframe √∫nico que √© gravado em uma tabela delta chamada bronze_brewery.

Brewery_Silver l√™ a tabela bronze_brewery que esta no delta e divide esse dataframe em dataframes particionados por pa√≠s.

Brewery_Gold l√™ a tabela bronze_brewery e cria uma tabela com as colunas relevantes gold, essa tabela ser√° consumida no power BI.

O c√≥digo dos tr√™s notebooks est√£o compartilhados na pasta source code. 

Todos os c√≥digos foram feitos em Python e Pyspark.

Abaixo imagem das tabelas criadas no delta.

![armazenamento delta](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/bf6de641-0d2a-4d6c-aa04-7ca8bb19e839)


‚óè Testes Automatizados no Docker

Foi implementado em uma vers√£o atualizada do projeto testes automatizados para transforma√ß√µes em Spark, rodando via Docker usando a imagem Bitnami Spark.
Imagen Docker: https://github.com/bitnami/containers/tree/main/bitnami/spark

Com os comandos abaixo constroi o container e roda o test_transformations.py:
docker build -t spark-tests .
docker run --rm spark-tests

A imagem abaixo mostra os testes PySpark rodando automaticamente assim que o container √© iniciado:

![Testes rodando automaticamente](https://github.com/user-attachments/assets/6cfdbf55-fcf7-4bbc-9fb0-a48f54cc9e5b)

o comando CMD ["pytest", "tests/test_transformations.py"] automatiza o docker.
√â preciso apenas dar um docker run que o arquivo test_transformations.py ira rodar os testes com Pytest.

üì¶Open-Brewery-DB_Azure-ELT
‚î£ üìÇtests
‚îÉ ‚îó üìútest_transformations.py
‚î£ üìúDockerfile
‚î£ üìúREADME.md



‚óè Visualiza√ß√£o dos dados atrav√©s de um Dashboard no PowerBI:


Para visualizar e tirar alguns insights desse escopo de dados, montei um dashboard que mostra a agrega√ß√£o da quantidade de Breweries de acordo com a sua localiza√ß√£o e do seu tipo, segue abaixo a imagem da pagina de an√°lise.

Filtrado para todos os cen√°rios:

![power bi dashboard total](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/9210b398-2f54-41b6-b3ca-43e8b8f28d01)


Filtrado para o pa√≠s South Korea:

![power bi dashboard korea](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/f5542219-94ce-455c-9369-f850a17ed3ab)


Filtrado por Brewery Type igual a large:

![power bi dashboard type large](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/79e77807-46e2-4df4-8401-c82c0b66a729)


Custos do projeto: Abaixo imagem que mostra os custos desse ELT feito totalmente no Azure.

![custo](https://github.com/vitornimschofsky/Open-Brewery-DB_Azure-ELT/assets/89933194/70063c62-10aa-4ccd-925d-768e3f01006a)



